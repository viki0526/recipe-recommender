{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "import inflect\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For cleaning up recipe titles\n",
    "def remove_extra_whitespace(input_string):\n",
    "    cleaned_string = re.sub(r'\\s+', ' ', input_string.strip())\n",
    "    return cleaned_string.lower()\n",
    "\n",
    "def replace_non_alpha_parentheses(input_string):\n",
    "    cleaned_string = re.sub(r'[^a-zA-Z() ]', '', input_string)\n",
    "    return cleaned_string\n",
    "\n",
    "def remove_null_chars(s):\n",
    "    new_list = []\n",
    "    for x in s:\n",
    "        if '\\x00' in x:\n",
    "            new_list.append(x.replace('\\x00', \"\"))\n",
    "        else:\n",
    "            new_list.append(x)\n",
    "    return new_list\n",
    "#-----------------------------#\n",
    "\n",
    "def remove_non_alphabet(s):\n",
    "    return {re.sub(r'[^a-zA-Z ]', '', word) for word in s}\n",
    "\n",
    "def check_ingredients(s, ings):\n",
    "    food_items = s.intersection(ings)\n",
    "    return food_items\n",
    "\n",
    "def get_ingredients():\n",
    "    p = inflect.engine()\n",
    "    with open('train.json', 'r') as file:\n",
    "        data = json.load(file)\n",
    "    ings = set()\n",
    "    for recipe in data:\n",
    "        s = recipe[\"ingredients\"]\n",
    "        ings.update(s)\n",
    "    opposite = set()\n",
    "    for x in ings:\n",
    "        alt = None\n",
    "        if p.singular_noun(x):\n",
    "            alt = p.singular_noun(x)\n",
    "        else:\n",
    "            alt = p.plural(x)\n",
    "        if alt:\n",
    "            opposite.add(alt)\n",
    "    ings = ings.union(opposite)\n",
    "    return ings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('recipes_data.csv')\n",
    "# convert NER, ingredients, directions to appropriate data structures\n",
    "df['NER'] = df['NER'].apply(lambda x: set(ast.literal_eval(x)))\n",
    "df['ingredients'] = df['ingredients'].apply(lambda x: ast.literal_eval(x))\n",
    "df['directions'] = df['directions'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NER'] = df['NER'].apply(remove_non_alphabet)\n",
    "\n",
    "# Create validation set of over 1500 ingredients\n",
    "all_ingredients = get_ingredients()\n",
    "\n",
    "# Clean up NER column by matching to ingredient validation set\n",
    "df['NER'] = df['NER'].apply(lambda x: check_ingredients(x, all_ingredients))\n",
    "df = df[df['NER'] != set()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes for each table\n",
    "\n",
    "ingredients_df = pd.DataFrame(list(all_ingredients), columns=['name'])\n",
    "\n",
    "recipes_df = df.drop(columns=['source']).rename(columns={'title': 'name'})\n",
    "recipes_df['name'] = recipes_df['name'].apply(lambda x: remove_extra_whitespace(replace_non_alpha_parentheses(x)))\n",
    "recipes_df = recipes_df[recipes_df['name'] != '']\n",
    "recipes_df['directions'] = recipes_df['directions'].apply(remove_null_chars)\n",
    "recipes_df = recipes_df.rename(columns = {'index': 'id', 'NER': 'ingredient_names'})\n",
    "recipes_df = recipes_df.groupby('name').filter(lambda group: len(group) > 2)\n",
    "recipes_df = recipes_df.reset_index()\n",
    "recipes_df['id'] = recipes_df.index\n",
    "recipes_df = recipes_df[['id', 'name', 'ingredient_names', 'ingredients', 'directions', 'link', 'site']]\n",
    "recipes_df['ingredient_names'] = recipes_df['ingredient_names'].apply(lambda x: list(x))\n",
    "\n",
    "# recipe_ingredients_df = recipes_df.copy()\n",
    "# recipe_ingredients_df = recipe_ingredients_df.explode('NER')\n",
    "# recipe_ingredients_df['recipe_id'] = recipe_ingredients_df.index\n",
    "# recipe_ingredients_df = recipe_ingredients_df.drop(columns=['name', 'ingredients', 'directions', 'link', 'site']).rename(columns={'NER': 'ingredient'}).reset_index()\n",
    "# recipe_ingredients_df = recipe_ingredients_df[['recipe_id', 'ingredient']]\n",
    "\n",
    "# recipes_df = recipes_df.drop(columns=['NER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed: Error 401\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "api_url = 'https://trackapi.nutritionix.com/v2/natural/nutrients'\n",
    "app_id = '4a922d3b'\n",
    "app_key = '581d2bca47024d1740305fde31226677'\n",
    "query = '1 cup rice'\n",
    "headers = {\n",
    "    'Content-Type' : 'application/json',\n",
    "    \"x-app-id\": app_id,\n",
    "    \"x-app-key\": app_key\n",
    "}\n",
    "params = {\n",
    "    \"query\": query\n",
    "}\n",
    "response = requests.post(api_url, json=params, headers=headers)\n",
    "if response.status_code == 200:\n",
    "    data = response.text\n",
    "    food_names = re.findall(r'\"food_name\":\"(.*?)\"', data)\n",
    "    print(food_names)\n",
    "else:\n",
    "    print(f'Request failed: Error {response.status_code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cheese\n",
      "{'cheeses', 'cheese'}\n",
      "bro\n",
      "{'brok', 'bros', 'brock', 'bloc', 'croc', 'bro', 'roc', 'brow', 'bronc'}\n",
      "parley\n",
      "{'parley', 'parsec', 'parsley', 'parse'}\n"
     ]
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell = SpellChecker()\n",
    "misspelled = spell.unknown(['parsey', 'cheesse', 'broc'])\n",
    "\n",
    "for word in misspelled:\n",
    "    # Get the one `most likely` answer\n",
    "    print(spell.correction(word))\n",
    "    # Get a list of `likely` options\n",
    "    print(spell.candidates(word))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
